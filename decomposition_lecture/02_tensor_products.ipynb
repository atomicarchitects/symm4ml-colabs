{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Tensor Products and Clebsch–Gordan Decomposition\n",
    "\n",
    "**6.7970/8.750 Symmetry and its Application to Machine Learning**\n",
    "\n",
    "Continuing with $D_4$ from Part 1, we explore how irreps combine under **tensor products**. By the end you will:\n",
    "\n",
    "1. Understand what a tensor product representation is and how to compute it\n",
    "2. Decompose tensor products back into irreps (the **Clebsch–Gordan problem**)\n",
    "3. Build the full **irrep multiplication table** for $D_4$\n",
    "4. Verify results using characters (the shortcut!)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/atomicarchitects/symm4ml-colabs/blob/main/decomposition_lecture/02_tensor_products.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install https://symm4ml.mit.edu/_static/symm4ml_s26/symm4ml/symm4ml_latest.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from symm4ml import groups, linalg, rep, vis\n",
    "from symm4ml.utils import match_character_tables, print_character_table, print_multiplication_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Recap: $D_4$ and its irreps\n",
    "\n",
    "We rebuild $D_4$ and find its irreps in standard order (see Part 1 for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build D4\n",
    "C4 = np.array([[np.cos(np.pi/2), -np.sin(np.pi/2)],\n",
    "               [np.sin(np.pi/2),  np.cos(np.pi/2)]])\n",
    "sigma_v = np.array([[-1., 0.], [0., 1.]])\n",
    "D4 = np.array(groups.generate_group(np.array([sigma_v, C4]))[::-1])\n",
    "table_D4 = groups.make_multiplication_table(D4)\n",
    "h = len(table_D4)\n",
    "\n",
    "# Find and label irreps (see Part 1 for the matching procedure)\n",
    "np.random.seed(42)\n",
    "D4_irreps_raw = rep.infer_irreps(table_D4)\n",
    "\n",
    "# Reorder to standard: A1, A2, B1, B2, E\n",
    "conj_classes = groups.conjugacy_classes(table_D4)\n",
    "conj_list = list(conj_classes)\n",
    "char_table = rep.character_table(D4_irreps_raw, conj_list)\n",
    "\n",
    "ref_chars = np.array([\n",
    "    [1,  1,  1,  1,  1],   # A1\n",
    "    [1,  1,  1, -1, -1],   # A2\n",
    "    [1, -1,  1,  1, -1],   # B1\n",
    "    [1, -1,  1, -1,  1],   # B2\n",
    "    [2,  0, -2,  0,  0],   # E\n",
    "])\n",
    "\n",
    "row_perm, col_perm = match_character_tables(char_table, ref_chars)\n",
    "\n",
    "names = ['A\\u2081', 'A\\u2082', 'B\\u2081', 'B\\u2082', 'E']\n",
    "irreps = [D4_irreps_raw[i] for i in row_perm]\n",
    "conj_std = [conj_list[j] for j in col_perm]\n",
    "\n",
    "print(\"D\\u2084 irreps in standard order:\")\n",
    "for name, ir in zip(names, irreps):\n",
    "    print(f\"  {name}: dim {ir.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. What is a tensor product representation?\n",
    "\n",
    "Given two representations $\\Gamma_i$ (dim $\\ell_i$) and $\\Gamma_j$ (dim $\\ell_j$), their **tensor product** $\\Gamma_i \\otimes \\Gamma_j$ is a new representation of dimension $\\ell_i \\cdot \\ell_j$, defined by:\n",
    "\n",
    "$$(\\Gamma_i \\otimes \\Gamma_j)(g) = \\Gamma_i(g) \\otimes \\Gamma_j(g)$$\n",
    "\n",
    "where $\\otimes$ on the right is the **Kronecker product** of matrices.\n",
    "\n",
    "Let's start with a simple example: $A_2 \\otimes E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = irreps[1]  # dim 1\n",
    "E  = irreps[4]  # dim 2\n",
    "\n",
    "A2_x_E = rep.tensor_product(A2, E)\n",
    "print(f\"A\\u2082 shape: {A2.shape}  (dim {A2.shape[1]})\")\n",
    "print(f\"E  shape: {E.shape}  (dim {E.shape[1]})\")\n",
    "print(f\"A\\u2082 \\u2297 E shape: {A2_x_E.shape}  (dim {A2_x_E.shape[1]})\")\n",
    "\n",
    "print(f\"\\nIs A\\u2082 \\u2297 E a valid representation? {rep.is_a_representation(table_D4, A2_x_E)}\")\n",
    "print(f\"Is it irreducible?  {rep.is_an_irrep(table_D4, A2_x_E)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A_2 \\otimes E$ is 2-dimensional and irreducible — so it must be isomorphic to $E$ itself (the only 2D irrep of $D_4$). Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"A\\u2082 \\u2297 E \\u2245 E?  {rep.are_isomorphic(A2_x_E, E)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense: multiplying by the 1D sign representation just flips some signs but doesn't change the dimension or structure of $E$.\n",
    "\n",
    "---\n",
    "## 3. A more interesting example: $E \\otimes E$\n",
    "\n",
    "The tensor product of the 2D irrep with itself gives a **4-dimensional** representation. This one *cannot* be irreducible (the largest irrep of $D_4$ is 2D), so it must decompose into smaller pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_x_E = rep.tensor_product(E, E)\n",
    "print(f\"E \\u2297 E shape: {E_x_E.shape}  (dim {E_x_E.shape[1]})\")\n",
    "print(f\"Is it irreducible?  {rep.is_an_irrep(table_D4, E_x_E)}\")\n",
    "print(f\"\\nLet's look at the matrices:\")\n",
    "vis.plot_matrices(E_x_E, figsize=(12, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing $E \\otimes E$\n",
    "\n",
    "We use `rep.decompose_rep_into_irreps` to find the irreducible pieces, then identify each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_irreps = rep.decompose_rep_into_irreps(E_x_E)\n",
    "\n",
    "print(f\"E \\u2297 E decomposes into {len(sub_irreps)} irreps:\\n\")\n",
    "for k, sub in enumerate(sub_irreps):\n",
    "    # Identify which standard irrep this matches\n",
    "    label = '?'\n",
    "    for name, ir in zip(names, irreps):\n",
    "        if rep.are_isomorphic(sub, ir):\n",
    "            label = name\n",
    "            break\n",
    "    print(f\"  Component {k+1}: dim {sub.shape[1]}  \\u2192  {label}\")\n",
    "\n",
    "dims = [s.shape[1] for s in sub_irreps]\n",
    "print(f\"\\nDimension check: {' + '.join(map(str, dims))} = {sum(dims)} = dim(E\\u2297E) = {E_x_E.shape[1]}  \\u2713\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $E \\otimes E = A_1 \\oplus A_2 \\oplus B_1 \\oplus B_2$. All four 1D irreps appear!\n",
    "\n",
    "This is a key result: the tensor product of the 2D irrep with itself contains every 1D irrep exactly once.\n",
    "\n",
    "---\n",
    "## 4. The character shortcut\n",
    "\n",
    "Computing tensor products and decomposing them matrix-by-matrix works, but there's a much faster way using **characters**:\n",
    "\n",
    "$$\\chi_{\\Gamma_i \\otimes \\Gamma_j}(g) = \\chi_{\\Gamma_i}(g) \\cdot \\chi_{\\Gamma_j}(g)$$\n",
    "\n",
    "Characters of a tensor product are just the **product of characters**. And to decompose, we use the **orthogonality formula**:\n",
    "\n",
    "$$n_k = \\frac{1}{h} \\sum_g \\chi_{\\Gamma_k}^*(g) \\, \\chi_{\\text{product}}(g)$$\n",
    "\n",
    "Let's verify this for $E \\otimes E$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character table in standard order\n",
    "chi = rep.character_table(irreps, conj_list)\n",
    "class_sizes = np.array([len(cc) for cc in conj_list])\n",
    "\n",
    "# Characters of E (last row)\n",
    "chi_E = chi[4]  # E\n",
    "\n",
    "# Characters of E⊗E = product of characters\n",
    "chi_ExE = chi_E * chi_E\n",
    "print(f\"\\u03c7(E):     {np.round(chi_E.real, 1)}\")\n",
    "print(f\"\\u03c7(E\\u2297E):  {np.round(chi_ExE.real, 1)}\")\n",
    "\n",
    "# Decompose using orthogonality\n",
    "print(f\"\\nMultiplicity of each irrep in E\\u2297E:\")\n",
    "for i, name in enumerate(names):\n",
    "    n_i = np.sum(class_sizes * np.conj(chi[i]) * chi_ExE).real / h\n",
    "    print(f\"  n({name}) = {n_i:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The character method gives the same answer instantly, without ever computing the actual decomposition matrices!\n",
    "\n",
    "---\n",
    "## 5. The full irrep multiplication table\n",
    "\n",
    "Now let's compute **all** tensor products $\\Gamma_i \\otimes \\Gamma_j$ and build a complete multiplication table. We'll use both methods to cross-check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the full irrep multiplication table using the course library\n",
    "dp_table = rep.direct_product_table(irreps, names)\n",
    "\n",
    "# Format for printing: convert sets to ⊕-joined strings\n",
    "mul_table = [['⊕'.join(sorted(dp_table[i, j])) for j in range(len(names))]\n",
    "             for i in range(len(names))]\n",
    "\n",
    "print_multiplication_table(mul_table, names, title=f\"Irrep multiplication table for D₄\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the table\n",
    "\n",
    "Key patterns to notice:\n",
    "- **$A_1$ is the identity**: $A_1 \\otimes \\Gamma = \\Gamma$ for all $\\Gamma$\n",
    "- **1D $\\times$ 1D = 1D**: Tensor products of 1D irreps give 1D irreps\n",
    "- **1D $\\times$ 2D = 2D**: $A_2 \\otimes E = E$, etc.\n",
    "- **$E \\otimes E$ is special**: It decomposes into all four 1D irreps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Same table from characters alone\n",
    "\n",
    "The character shortcut lets us build the entire table without ever constructing matrices. This is how it's done in practice for larger groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the same table using only characters (no matrix decomposition needed!)\n",
    "mul_table_chi = []\n",
    "for i in range(len(names)):\n",
    "    row = []\n",
    "    for j in range(len(names)):\n",
    "        chi_prod = chi[i] * chi[j]\n",
    "        labels = []\n",
    "        for k in range(len(names)):\n",
    "            n_k = int(round(np.sum(class_sizes * np.conj(chi[k]) * chi_prod).real / h))\n",
    "            labels.extend([names[k]] * n_k)\n",
    "        row.append('⊕'.join(sorted(labels)))\n",
    "    mul_table_chi.append(row)\n",
    "\n",
    "print_multiplication_table(mul_table_chi, names, title=\"Multiplication table via characters\")\n",
    "print(\"\\n(Should match the table above exactly!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Visualizing the block-diagonal structure\n",
    "\n",
    "Let's see what $E \\otimes E$ looks like before and after decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"E \\u2297 E (scrambled):\")\n",
    "vis.plot_matrices(E_x_E, figsize=(12, 3));\n",
    "\n",
    "# Reconstruct as a direct sum of the identified irreps\n",
    "sub_irreps_ExE = rep.decompose_rep_into_irreps(E_x_E)\n",
    "direct = rep.direct_sum_multiple(sub_irreps_ExE)\n",
    "print(\"\\nE \\u2297 E (block-diagonalized):\")\n",
    "vis.plot_matrices(direct, figsize=(12, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After decomposition, we see four 1×1 blocks along the diagonal — the four 1D irreps $A_1, A_2, B_1, B_2$.\n",
    "\n",
    "---\n",
    "## Summary\n",
    "\n",
    "| Concept | What we learned |\n",
    "|---|---|\n",
    "| **Tensor product** | $\\Gamma_i \\otimes \\Gamma_j$ is a new rep of dim $\\ell_i \\cdot \\ell_j$ |\n",
    "| **Clebsch–Gordan decomposition** | Any tensor product decomposes into a direct sum of irreps |\n",
    "| **Character shortcut** | $\\chi(\\Gamma_i \\otimes \\Gamma_j) = \\chi(\\Gamma_i) \\cdot \\chi(\\Gamma_j)$, then use orthogonality |\n",
    "| **Multiplication table** | Captures all possible ways irreps combine — fundamental to building equivariant models |\n",
    "\n",
    "**Next up** (Part 3): We apply these tools to a larger group ($T_d$) to see how the algorithms scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
